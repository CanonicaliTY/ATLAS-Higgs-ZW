{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "043f9ec3-b8e2-4e53-9c9a-f907af7b185f",
   "metadata": {},
   "source": [
    "# About Jupyter Notebook\n",
    "For some of you, this might be your first time using a Jupyter notebook. Here are a few tips to get you started!\n",
    "\n",
    "A Jupyter notebook is a file with the .ipynb extension, just like this one. It's made up of *cells*, which can be:\n",
    "- Code cells - where you write your code\n",
    "- Markdown cells - where you write formatted text (like this section!)\n",
    "\n",
    "Code cell are labeled with `[ ]` on the left. When a cell is running, the label changes to `[*]`. The number inside the brackets shows the order in which cells have been executed by the *kernel*.\n",
    "\n",
    "So, what is the kernel? The kernel is the computational 'engine' that runs the code. This notebook is connected to a Python kernel.\n",
    "\n",
    "### Useful Keyboard Shortcuts\n",
    "Jupyter notebooks offer helpful keyboard shortcuts that may save your time. First, make sure you are in *command mode* (not editing a cell). Press <kbd>Esc</kbd> or click outside the cell to exit *edit mode*.\n",
    "\n",
    "Here are some handy shortcuts:\n",
    "- Insert a new cell above or below → press <kbd>A</kbd> or <kbd>B</kbd>\n",
    "- Delete a cell → press <kbd>D</kbd> twice (Note: Deleted cells cannot be recovered!)\n",
    "- Restart the kernel and run all cells → press <kbd>0</kbd> twice (this is a zero!)\n",
    "- Run the selected cell → press <kbd>Ctrl</kbd> + <kbd>Enter</kbd>\n",
    "- Run the selected cell and move to the next cell → press <kbd>Shift</kbd> + <kbd>Enter</kbd>\n",
    "\n",
    "Please check out the toolbar and menu bar at the top of the notebook for more options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcca48-33fc-4422-91bf-f61283222400",
   "metadata": {},
   "source": [
    "# Awkward Arrays\n",
    "This lab uses a library called **Awkward Array**. Like Numpy, Awkward Arrays can have multiple dimensions. However, unlike Numpy, Awkward arrays support dimensions with *varying lengths*, making them ideal for handling irregular or nested data in particle physics experiments.\n",
    "### Structured Data in Awkward Arrays\n",
    "This lab uses structured data, where each element is a *record* with named fields (similar to a dictionary). For example:\n",
    "```\n",
    "array1 = ak.Array([{\n",
    "    'a': [1, 2, 3],\n",
    "    'b': 4,\n",
    "    'c': [5, 6]\n",
    "}])\n",
    "```\n",
    "This array `array1` contains *one* record with three fields: `'a'`, `'b'`, and `'c'`. You can access the list of fields with `array1.fields`.\n",
    "### Concatenating Awkward Arrays\n",
    "To combine two Awkward arrays with matching structure, use `ak.concatenate()`. An example:\n",
    "```\n",
    "array2 = ak.Array([{\n",
    "    'a': [7, 8],\n",
    "    'b': 9,\n",
    "    'c': [10, 11, 12]\n",
    "}])\n",
    "\n",
    "ak.concatenate([array1, array2])\n",
    "```\n",
    "This results in a single Awkward Array with *two* records:\n",
    "```\n",
    "[\n",
    "    {'a': [1, 2, 3], 'b': 4, 'c': [5, 6]},\n",
    "    {'a': [7, 8],    'b': 9, 'c': [10, 11, 12]}\n",
    "]\n",
    "```\n",
    "For more information about Awkward Arrays: https://awkward-array.org/doc/main/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a081d97-05f2-4e03-bea0-aeb2b493ae40",
   "metadata": {},
   "source": [
    "# The Experiment\n",
    "This experiment uses custom modules in the *backend* folder, which have been specifically developed for this third-year lab. This notebook works with **pre-processed data** derived from the **13 TeV 2025 ATLAS Open Data**.\n",
    "\n",
    "Please run the cell below to install the required packages. You will need to do this **each time you start the server**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134dc01-a41c-41b7-b327-2d167cf7ab86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install atlasopenmagic\n",
    "!pip install pyarrow==20.0.0\n",
    " \n",
    "from atlasopenmagic import install_from_environment\n",
    "install_from_environment(environment_file=\"../backend/environment.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a381be-130e-4341-b8ee-a1e191e49d67",
   "metadata": {},
   "source": [
    "The above cell is likely to take about 30 seconds to run.  Wait until the [*] to the left of the above cell becomes a number, indicating that it has finished running.  Then, run the cell below to import the required modules and functions for the experiment. Repeat this step **every time you restart the kernel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4c54d-6689-434e-909c-06b02edf1be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import awkward as ak\n",
    "import time\n",
    "import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import uproot\n",
    "import glob\n",
    "import numpy as np\n",
    "import vector\n",
    "import hist\n",
    "from hist import Hist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from backend import get_valid_variables, validate_read_variables\n",
    "from backend import plot_stacked_hist, plot_histograms, histogram_2d, plot_errorbars\n",
    "from backend import get_histogram, analysis_parquet, VALID_STR_CODE, produced_event_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d3f6f-6971-40a1-a03f-fbc25821b8af",
   "metadata": {},
   "source": [
    "## Accessing Data Samples\n",
    "Data samples stored in the folder *backend/parquet* can be accessed using a *string code*. The available string codes are listed below:  \n",
    "#### Available Final-State Collections (Real Data)\n",
    "* `'2to4lep'` - Events with two to four leptons, each with at least 7 GeV of transverse momentum $p_T$\n",
    "* `'GamGam'` - Events with at least two photons, each with at least 25 GeV of $p_T$\n",
    "\n",
    "#### Available Monte Carlo Simulation Datasets include\n",
    "* `'Zee'` - Simulated $Z \\rightarrow e^+e^-$ events\n",
    "* `'Zmumu'` - Simulated $Z \\rightarrow \\mu^+\\mu^-$ events\n",
    "* `'Ztautau'` - Simulated $Z \\rightarrow \\tau^+\\tau^-$ events\n",
    "* `'ttbar'` - Simulated $t\\overline{t}$ events\n",
    "* `'Hyy'` - Simulated $H \\rightarrow \\gamma \\gamma$ events\n",
    "\n",
    "You can use the function `VALID_STR_CODE` to view all available string codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d9983-551c-4b6b-99f0-66c6898e847b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VALID_STR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ea157-9569-4601-92cb-0d10c09f91f8",
   "metadata": {},
   "source": [
    "To combine multiple datasets, combine the string codes using `'+'`. For example, if you would like to combine the $Z \\rightarrow \\mu^+\\mu^-$ and $Z \\rightarrow e^+e^-$ datasets, use the string code `'Zee+Zmumu'`.\n",
    "\n",
    "The sample files in the folder *backend/parquet* contain records, each of which corresponds to an individual LHC *event*. The record for each *event* contains information about the leptons and/or photons found in that event. You can view the available variables using the `get_valid_variables` function that is defined in the folder *backend*. An example is shown in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e31b7f-adf5-421d-bc40-8ec78a836cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_code = '2to4lep'\n",
    "get_valid_variables(string_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627a445-b99d-4793-9b9f-6ca748df1236",
   "metadata": {},
   "source": [
    "The function `analysis_parquet` reads datasets specified by the `string_code_list` input and returns a dictionary containing the selected data. By default the selected data is stored in memory for subsequent histogramming/fitting. The parameter `fraction` determines the fraction of each dataset to load; the default value is `1`. For di-lepton analysis, it is recommended to start with `fraction = 0.01` or lower to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb4d91-218d-4ed0-bdd0-cb787841a2e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_code_list = ['2to4lep', 'Zee'] # List of dataset codes to load\n",
    "read_variables = ['lep_n', 'lep_pt']\n",
    "fraction = 0.01 # Fraction of each dataset to load\n",
    "# Call analysis_parquet to read the datasets and return the data as a dictionary\n",
    "data = analysis_parquet(read_variables, string_code_list, fraction=fraction)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f9665-6168-473c-b5c0-9e56bbadcbce",
   "metadata": {},
   "source": [
    "As shown in the example above, the `analysis_parquet` function returns a dictionary where:\n",
    "- **Keys** are constructed by combining each dataset code from `string_code_list` with the `fraction` (e.g. for `2to4lep` and `fraction = 0.01`, the key is `'2to4lep_0_01`)\n",
    "- **Values** are Awkward Arrays, where each entry corresponds to an event represented as a record (similar to a Python dictionary). The fields in each record correspond to the variables listed in `read_variables`.\n",
    "\n",
    "For example, the dictionary returned by the `analysis_parquet` may look like this:\n",
    "```\n",
    "data = {\n",
    "    '2to4lep_0_01': Array([\n",
    "        {'lep_n': 2, 'lep_pt': [106, 47.6]},\n",
    "        {'lep_n': 2, 'lep_pt': [41.6, 37.3]},\n",
    "    ]),\n",
    "    'Zee_0_01': Array([\n",
    "        ...\n",
    "    ])\n",
    "}\n",
    "```\n",
    "\n",
    "Let's interpret the first event in the `'2to4lep_0_01'` dataset, which is represented by the first record in the Awkward Array stored under the `'2to4lep_0_01'` key (i.e., `data['2to4lep_0_01']`).\n",
    "- The number of leptons in this event is 2 (`lep_n : 2`)\n",
    "- The field `lep_pt` lists their transverse momenta: The first lepton has $p_T = 106$ GeV, and the second lepton has $p_T = 47.6$ GeV.\n",
    "\n",
    "To extract the $p_T$ of the first lepton from all events in the `'2to4lep_0_01'` dataset, use  \n",
    "`data['2to4lep_0_01']['lep_pt'][:, 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c34f22-a15d-42b1-b38b-67674d7fac7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['2to4lep_0_01']['lep_pt'][:, 0] # pT of the first lepton from all events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39216841-0faf-40ca-a879-d0dfaf21ab8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Event Weights\n",
    "For a variety of reasons each event in the MC data has an associated *weight*.  \n",
    "\n",
    "When an event from the ATLAS experiment data is added to one of your histograms then the relevant histogram bin is incremented by 1.0.  However, when using MC events the relevant histogram bin is incremented by an amount `'totalWeight'`.  \n",
    "\n",
    "You have access to 36 fb$^{-1}$ of real ATLAS data.  However, the MC samples for most of the physical processes have a larger number of events than would be expected in 36 fb$^{-1}$ of data.  The application of a weight (typically less than one) ensures that the total number of events you see in MC histograms is equal to that predicted for the equivalent ATLAS data set.  This calculation involves knowing the predicted cross section, $\\sigma$, for each considered physical process and the integrated luminosity, $\\int\\mathcal{L} dt$.  The *weight* also corrects for discrepancies in experimental efficiencies between the MC simulation and the real ATLAS detector.\n",
    "\n",
    "You don't need to explicitly include `'totalWeight'` in `read_variables`. If the field is present in the data (i.e. in MC samples), `analysis_parquet` will return it automatically.\n",
    "\n",
    "Take a look the `EventWeights` module in the backend folder if you're curious how the variable is calculated!\n",
    "\n",
    "**_Tip_**: Please be careful not to edit any of the code in the backend folder – unless you really know what you are doing you could cause the code to perform in unexpected ways!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa601cc-92aa-41d5-aeac-6156d22ad973",
   "metadata": {},
   "source": [
    "## Event Selection\n",
    "\n",
    "You can also perform event selection by defining a custom *cut function*, which can be passed to `analysis_parquet` via the argument `cut_function`. This function takes the full dataset as input and returns a filtered version according to your selection criteria. In addition, you can compute new variables within the cut function and store them in memory as new fields in the event records. \n",
    "\n",
    "The example below selects events with exactly two final-state leptons. It then computes the invariant mass by summing their four-momentum vectors and accessing the `.M` attribute as implemented in the `dilep_cut` function. This function is passed to the `analysis_parquet` via the `cut_function` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac462563-1e06-4a18-b099-174debb8c2b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#string_code_list = ['2to4lep'] # List of dataset codes to load\n",
    "string_code_list = ['2to4lep', 'Zmumu', 'm10_40_Zmumu', 'Ztautau', 'ttbar', 'Wmunu'] # List of dataset codes to load\n",
    "\n",
    "# Variables to read from the dataset\n",
    "read_variables = ['lep_pt', 'lep_eta', 'lep_phi', 'lep_e', 'lep_type', 'lep_charge', 'lep_n', 'trigM', 'trigE']\n",
    "# , 'lep_isLooseID', 'lep_isMediumID', 'lep_isLooseIso', 'lep_isTightIso', 'lep_isTrigMatched']   # other variables that could be read in\n",
    "\n",
    "# You may also use the pre-defined function `validate_read_variables` to validate your `read_variables`. \n",
    "read_variables = validate_read_variables(string_code_list, read_variables)\n",
    "\n",
    "# Custom selection cut function to filter the data\n",
    "def pt_cut(data):\n",
    "    # Cut on lepton number - Only keep events that have two leptons\n",
    "    data = data[data['lep_n'] == 2] \n",
    "\n",
    "    # Cut on lep_type\n",
    "    # lep_type is 11 for electron, 13 for muon\n",
    "    data = data[data['lep_type'][:, 0] + data['lep_type'][:, 1] == 26] # Keep events with two muons\n",
    "\n",
    "    # Cuts on lepton pt\n",
    "    # Use bitwise operator '&' for AND, '|' for OR. Remember the parentheses!\n",
    "    data = data[(data['lep_pt'][:, 0] > 10) & (data['lep_pt'][:, 1] > 10)]   # Keep events where both leptons have pt > 10 GeV\n",
    "\n",
    "    # Require that a single muon trigger fired \n",
    "    data = data[(data['trigM'])] \n",
    "\n",
    "    # Define four momentum\n",
    "    four_momentum = vector.zip({\n",
    "        'pt': data['lep_pt'],\n",
    "        'eta' : data['lep_eta'],\n",
    "        'phi' : data['lep_phi'],\n",
    "        'E' : data['lep_e']\n",
    "    })\n",
    "    # Add the 4-momentum of the two leptons in each event and get the \n",
    "    # invariant mass using .M\n",
    "    data['mass'] = (four_momentum[:, 0] + four_momentum[:, 1]).M\n",
    "    \n",
    "    # Cut on di-lepton mass\n",
    "    cut_low = 0\n",
    "    cut_high = 1000   \n",
    "    cut_mass = (data['mass']>cut_low) &  (data['mass']<cut_high)\n",
    "    data = data[cut_mass] # Select events satisfying the condition: cut_low < mass < cut_high (GeV)\n",
    " \n",
    "    return data\n",
    "\n",
    "fraction = 0.02\n",
    "pt_data = analysis_parquet(read_variables, string_code_list, fraction=fraction, cut_function=pt_cut)\n",
    "pt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e375f78-6005-438c-99ee-e49556ec3384",
   "metadata": {},
   "source": [
    "If you only need data for a specific lepton — for example, the $p_T$ of the first lepton — you can include `'lepton_pt[0]'` in `read_variables` instead of `'lepton_pt'`. This saves memory by storing the data as a flat array rather than a nested one. However, do this only if `'lepton_pt'` is not required elsewhere, such as in the cut function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4dfe6-323d-48e5-92b2-a5e1df00be1d",
   "metadata": {},
   "source": [
    "## Plot Stacked Histogram\n",
    "The dictionary returned by `analysis_parquet` can be used to plot a stacked histogram by passing it to the `plot_stacked_hist` function.\n",
    "\n",
    "To use this function correctly, there are a few points to take note of:\n",
    "- The first argument must be a **dictionary**.\n",
    "- If a dictionary key includes `'Data'`, its content will be plotted as data points with error bars.\n",
    "- If a dictionary key includes `'Signal'`, its content will be stacked as histogram bars on top of the background.\n",
    "- Python strings are case-sensitive, i.e. `'Data'` and `'data'` are treated differently!\n",
    "\n",
    "An example is shown below, where `'2to4lep_0_01'` is treated as data and `'Zee_0_01'` as the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbdd532-8692-4806-a159-07efe5f0db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what to plot: '2to4lep_0_01' as data, 'Zee_0_01' as signal\n",
    "plot_dict = {\n",
    "    'Data' : pt_data['2to4lep_0_02'],\n",
    "    'Signal Zmumu' : pt_data['Zmumu_0_02'], \n",
    "    'Signal m10_40_Zmumu' : pt_data['m10_40_Zmumu_0_02'], \n",
    "    'Background Ztautau': pt_data['Ztautau_0_02'],\n",
    "    'Background ttbar' : pt_data['ttbar_0_02'], \n",
    "    'Background Wmunu' : pt_data['Wmunu_0_02'],\n",
    "}\n",
    "\n",
    "# Define plot appearance\n",
    "#color_list = ['k'] # Black (data)\n",
    "color_list = ['k', 'b', 'y', 'g', 'r', 'm'] # Black (data), blue (signal), yellow (signal), green (Ztautau), red (ttbar), magenta (Wmunu')\n",
    "\n",
    "# Variable to plot on the x-axis\n",
    "plot_variable = 'mass'\n",
    "\n",
    "xmin, xmax = 0, 120 # Define histogram bin range and x-axis limits \n",
    "num_bins = 120 # Number of histogram bins\n",
    "x_label = 'mass [GeV]' # x-axis label \n",
    "\n",
    "# Plot the histogram\n",
    "fig, hists = plot_stacked_hist(plot_dict, plot_variable, color_list,\n",
    "                               num_bins, xmin, xmax, x_label, logy=True, show_text=True, residual_plot=True, save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0600c08-b14c-471c-91bb-e2c77f0f0107",
   "metadata": {},
   "source": [
    "The `plot_stacked_hist` function accepts several optional parameters that allow you to customise the appearance and behaviour of the plot:\n",
    "- `y_label` : Label for the y-axis\n",
    "- `ylim` : Tuple of two numbers for y-axis limits\n",
    "- `logy` : Set to `True` to use a logarithmic y-axis\n",
    "- `title` : Title of the plot\n",
    "- `marker` : Marker style for the data points (default: `'o'`)\n",
    "- `fig_size` : Tuple of two numbers for the figure size (default: `(12, 8)`)\n",
    "- `show_text` : Set to `True` to display text annotations (histogram information) on the plot\n",
    "- `show_back_unc` : Set to `False` to hide background uncertainty\n",
    "- `save_fig` : Set to `True` to save the figure\n",
    "- `fig_name` : String filename to save the plot as an image\n",
    "- `residual_plot` : Set to `True` to add a residual plot (Data / MC) below the main plot\n",
    "- `residual_plot_ylim` : Tuple of two numbers for residual plot y-axis limits\n",
    "- `title_fontsize` : Font size for the plot title (default: 17)\n",
    "- `label_fontsize` : Font size for the x and y axis labels (default: 17)\n",
    "- `legend_fontsize` : Font size for the legend (default: 17)\n",
    "- `tick_labelsize` : Font size for the axis tick labels  (default: 15)\n",
    "- `text_fontsize` : Font size for text annotations (default: 14)\n",
    "\n",
    "The function returns a `Figure` object and a **list** of `Hist` objects corresponding to each dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57201a6f-03f6-4627-8531-bbbbe00a7c08",
   "metadata": {},
   "source": [
    "## Hist\n",
    "`Hist` objects can be used to inspect the histogram contents, including the bin values, variances (for MC datasets), and underflow/overflow bins.  \n",
    "The second value returned by `plot_stacked_hist` is a list of `Hist` objects. They are in the order 'Data', 'Background', 'Signal'.\n",
    "\n",
    "Here are some useful methods:\n",
    "- `.sum()` - total sum of all bin contents\n",
    "- `.view()` - bin values (Data)\n",
    "- `.view().value` - bin values (MC)\n",
    "- `.view().variance` - bin variances (MC)\n",
    "- `.view(flow=True)[0]` - underflow bin value\n",
    "- `.view(flow=True)[-1]` - overflow bin value\n",
    "- `.axes[0].centers` - bin centres\n",
    "  \n",
    "For example, try uncommenting the lines below to explore the contents of a `Hist` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d101e8d-1864-4a77-8f46-8db00fb0cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our example, the first Hist object (index 0) is Data, and the second (index 1) is MC\n",
    "hists                 # View the full histogram object\n",
    "#hists[2]                 # View the full histogram object\n",
    "# hists[0].sum()         # Total sum of all bin contents\n",
    "# hists[0].view()        # Access the bin values (excluding flow bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0f0b7-b977-4ffe-b50c-fa880fc4bebc",
   "metadata": {},
   "source": [
    "For more information about `Hist`, see https://hist.readthedocs.io/en/latest/.\n",
    "\n",
    "For more information about `matplotlib.pyplot`, see https://matplotlib.org/stable/api/pyplot_summary.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4bd9b-18c3-4216-a234-f041f9e375f8",
   "metadata": {},
   "source": [
    "The function `savefig` saves a copy of the figure you have just produced.\n",
    "    Note an alternative is to set the input argument `save_fig` to `True` in the function `plot_stacked_hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639fee7-65f4-4073-9d1f-f40efe6229c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(plot_variable+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d9802-8e37-4e20-bd29-79532c582bfc",
   "metadata": {},
   "source": [
    "## Additional Plotting Functions\n",
    "If you want to plot additional variables to identify where the selection cut could be tightened, the `plot_histograms` function is for you. This function returns:\n",
    "- A **list** of `Figure` objects (one per variable plotted)\n",
    "- A corresponding **list of lists** of `Hist` objects\n",
    "\n",
    "There are some arguments worth pointing out:\n",
    "- `xmin_xmax_list` : a tuple of two numbers applied to all plots, or a list of tuples (one per variable)\n",
    "- `num_bins_list` : an int applied to all plots, or a list of int (one per variable)\n",
    "\n",
    "The same applies to these optional arguments: `y_label_list`, `ylim_list`, `title_list`, and `residual_ylim_list`. These can be specified as a single value applied to all plots or as a list matching the number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610e3b7-ee8e-446b-a2e3-c9042a1efc1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot many variables at once \n",
    "plot_dict = {\n",
    "    'Data' : pt_data['2to4lep_0_02'],\n",
    "    'Signal Zmumu' : pt_data['Zmumu_0_02'], \n",
    "    'Signal m10_40_Zmumu' : pt_data['m10_40_Zmumu_0_02'], \n",
    "    'Background Ztautau': pt_data['Ztautau_0_02'],\n",
    "    'Background ttbar' : pt_data['ttbar_0_02'], \n",
    "    'Background Wmunu' : pt_data['Wmunu_0_02'],\n",
    "}\n",
    "\n",
    "# Define plot appearance\n",
    "#color_list = ['k'] # Black (data)\n",
    "color_list = ['k', 'b', 'y', 'g', 'r', 'm'] # Black (data), blue (signal), yellow (signal), green (Ztautau), red (ttbar), magenta (Wmunu')\n",
    "\n",
    "\n",
    "plot_variables = ['lep_pt[0]', 'lep_pt[1]', 'lep_eta[0]', 'lep_eta[1]']\n",
    "xmin_xmax_list = [(10, 100), (10, 100), (-3, 3), (-3, 3)] # Bin range for each variable\n",
    "num_bins_list = 100\n",
    "x_label_list = ['lep_pt[0] [GeV]', 'lep_pt[1] [GeV]', 'lep_eta[0]', 'lep_eta[1]']\n",
    "\n",
    "plot_histograms(\n",
    "    plot_dict,\n",
    "    plot_variables,\n",
    "    color_list,\n",
    "    xmin_xmax_list, # If you provide a tuple of 2 numbers, that will be applied to all plots\n",
    "    num_bins_list,\n",
    "    x_label_list,\n",
    "    # Optional arguments start from here\n",
    "    # y_label_list=None, # Str or list of str for y-axis label\n",
    "    # ylim_list=None, # Tuple of 2 numbers or list of tuples for y axis limit\n",
    "    logy=False, # Whether to set the y axis as log scale\n",
    "    # title_list=None, # Str or list of str for title\n",
    "    # marker='o', # Marker type\n",
    "    # title_fontsize=17, # Fontsize for title\n",
    "    # label_fontsize=17, # Fontsize for x and y axes\n",
    "    # legend_fontsize=17, # Fontsize for legend\n",
    "    # tick_labelsize=15, # Fontsize for x and y axes ticks\n",
    "    # text_fontsize=14, # Fontsize for text that shows histogram info\n",
    "    # fig_size=(12, 8), # Figure size\n",
    "    # show_text=False, # Whether to show the text that displays histogram info\n",
    "    # show_back_unc=True, # Whether to show the background uncertainty\n",
    "    save_fig=False, # Whether to save figure\n",
    "    # fig_name=None, # Filename of the image. If not provided, save figure using the plot_variable and the keys of data_dict\n",
    "    residual_plot=False # Whether to show residual plot under the main plot\n",
    "    # residual_ylim_list=None # Tuple of 2 numbers or list of tuples for residual plot y-axis limit\n",
    ")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6ff71-4cfb-41df-9204-7fffd6f81396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604a3d31-928e-4f19-b4bd-e61098be7718",
   "metadata": {},
   "source": [
    "The `plot_errorbars` function is designed for situations where you want to:\n",
    "- Plot the same variable for different particles in the same event on a single figure, or\n",
    "- Compare histograms under different selection cuts.\n",
    "\n",
    "The first argument to `plot_errorbars` must be a dictionary. Each value in this dictionary should also be a dictionary containing the following keys:\n",
    "- `'color'`: Color to be used for plotting\n",
    "- `'array'`: The data array to be histogrammed\n",
    "- `'weight'`: Weights associated with each data point\n",
    "\n",
    "This function returns:\n",
    "- A `Figure` object (for saving), and\n",
    "- A list of `Hist` objects representing the histograms for each key\n",
    "\n",
    "Below are some examples demonstrating how to use the `plot_errorbars` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595a8a0-b8ca-4710-9219-6a7ab9518998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pt of the two leptons\n",
    "data_dict = {\n",
    "    'Data  pt[0]' : {'color' : 'r',\n",
    "                          'array' : pt_data['2to4lep_0_02']['lep_pt'][:, 0],\n",
    "                          'weight' : None},\n",
    "    'Data  pt[1]' : {'color' : 'b',\n",
    "                          'array' : pt_data['2to4lep_0_02']['lep_pt'][:, 1],\n",
    "                          'weight' : None},\n",
    "    'Zmumu pt[0]' : {'color' : 'g',\n",
    "                         'array' : pt_data['Zmumu_0_02']['lep_pt'][:, 0],\n",
    "                         'weight' : pt_data['Zmumu_0_02']['totalWeight']},\n",
    "    'Zmumu pt[1]' : {'color' : 'm',\n",
    "                         'array' : pt_data['Zmumu_0_02']['lep_pt'][:, 1],\n",
    "                         'weight' : pt_data['Zmumu_0_02']['totalWeight']},\n",
    "}\n",
    "xmin, xmax = 10, 120\n",
    "num_bins = 55\n",
    "x_label = 'lep_pt [GeV]'\n",
    "\n",
    "plot_errorbars(data_dict,\n",
    "               xmin,\n",
    "               xmax,\n",
    "               num_bins,\n",
    "               x_label,\n",
    "               # Optional arguments\n",
    "               # y_label='Events',\n",
    "               # logy=False,\n",
    "               # title='',\n",
    "               # marker='o',\n",
    "               # title_fontsize=17,\n",
    "               # label_fontsize=17,\n",
    "               # legend_fontsize=17,\n",
    "               # tick_labelsize=15,\n",
    "               # text_fontsize=14,\n",
    "               # show_text=False,\n",
    "               # fig_size=(12, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a80f3-d47c-442b-9cdc-acb518715f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second copy of the data in memory, having applied a different set of event selection cuts (from those applied above in function \"pt_cut()\"\n",
    "\n",
    "def pt20_cut(data):\n",
    "    # Cut on lepton number, type and pt\n",
    "    data = data[data['lep_n'] == 2] \n",
    "    data = data[data['lep_type'][:, 0] + data['lep_type'][:, 1] == 26]\n",
    "    data = data[(data['lep_pt'][:, 0] > 20) & (data['lep_pt'][:, 1] > 20)]\n",
    "\n",
    "    # Require that a single muon trigger fired \n",
    "    data = data[(data['trigM'])] \n",
    "\n",
    "    four_momentum = vector.zip({\n",
    "        'pt': data['lep_pt'],\n",
    "        'eta' : data['lep_eta'],\n",
    "        'phi' : data['lep_phi'],\n",
    "        'E' : data['lep_e']\n",
    "    })\n",
    "    # Add the 4-momentum of the two leptons in each event and get the \n",
    "    # invariant mass using .M\n",
    "    data['mass'] = (four_momentum[:, 0] + four_momentum[:, 1]).M\n",
    "    \n",
    "    return data\n",
    "\n",
    "pt20_data = analysis_parquet(read_variables, string_code_list, fraction=fraction, cut_function=pt20_cut)\n",
    "pt20_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40537752-ab76-411b-8a22-e4640cb5563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare histograms under different cuts\n",
    "data_dict = {\n",
    "    'Data pt>20' : {'color' : 'r',\n",
    "                    'array' : pt20_data['2to4lep_0_02']['mass'],\n",
    "                    'weight' : None},\n",
    "    'Zmumu pt>20' : {'color' : 'g',\n",
    "                   'array' : pt20_data['Zmumu_0_02']['mass'],\n",
    "                   'weight' : pt20_data['Zmumu_0_02']['totalWeight']},\n",
    "    'Data pt>10' : {'color' : 'b',\n",
    "                    'array' : pt_data['2to4lep_0_02']['mass'],\n",
    "                    'weight' : None},\n",
    "    'Zmumu pt>10' : {'color' : 'm',\n",
    "                   'array' : pt_data['Zmumu_0_02']['mass'],\n",
    "                   'weight' : pt_data['Zmumu_0_02']['totalWeight']},\n",
    "}\n",
    "\n",
    "xmin, xmax = 50, 140 # Define histogram bin range and x-axis limits \n",
    "num_bins = 90 # Number of histogram bins\n",
    "x_label = 'mass [GeV]'\n",
    "\n",
    "plot_errorbars(data_dict, xmin, xmax, num_bins, x_label, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea043e-f2d1-498d-919f-c6dd74a7b4a2",
   "metadata": {},
   "source": [
    "## 2D Histogram\n",
    "If you want to plot a 2D histogram, you can use the `histogram_2d` function as shown in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501be60a-7afc-419d-a62f-b15d2ad8427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_pt0 = pt_data['2to4lep_0_02']['lep_pt'][:, 0]\n",
    "data_pt1 = pt_data['2to4lep_0_02']['lep_pt'][:, 1]\n",
    "data_2d = (data_pt0, data_pt1) # Plot lep_pt[0] on x-axis, lep_pt[1] on y-axis\n",
    "num_bins_2d = (100, 100) # Number of bins along x and y-axis \n",
    "min_max_2d = ((10, 110), (10, 110)) # The bin range in x and y\n",
    "label_2d = ('$p_T$ [0]', '$p_T$ [1]') # The labels for x and y-axis\n",
    "\n",
    "\n",
    "# Plot the 2D histogram\n",
    "fig, h = histogram_2d(data_2d, num_bins_2d,\n",
    "                      min_max_2d, label_2d,\n",
    "                      # Optional arguments\n",
    "                      # label_fontsize=12, tick_labelsize=10,\n",
    "                      # title_fontsize=13, title='',\n",
    "                      # colorbar_label='Events'\n",
    "                    )\n",
    "# Uncomment to save the image\n",
    "#fig.savefig('test.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f91bb-fb8f-4281-a146-4f9b9673f2cb",
   "metadata": {},
   "source": [
    "## Write the Data to Disk\n",
    "When working with larger datasets, e.g. using a higher `fraction` in `analysis_parquet`, it is often more efficient to write the data to disk rather than keeping it all in memory. \n",
    "\n",
    "To do this, set the optional argument `write_parquet=True`. This will instruct the `analysis_parquet` function to save the output as Parquet files. If you write data to disk, it is recommended to set `return_output=False` to avoid loading large amounts of data into memory.  \n",
    "\n",
    "In addition, you can customise the output location using the `output_directory` argument. If not provided, the files will be saved in an `output` folder with a unique name created from the current date and time.  \n",
    "\n",
    "**Note**: The provided output directory must be unique and cannot be reused. Attempting to write to an existing directory will raise a `FileExistsError` to prevent accidental overwriting of data.   \n",
    "\n",
    "For example, the following makes a tighter preselection of di-lepton events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553de47e-c1ec-4d0a-a297-eb8f5fca3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own di-lepton preselection to parquet files\n",
    "\n",
    "string_code_list = ['2to4lep', 'Zmumu', 'm10_40_Zmumu', 'Ztautau', 'ttbar', 'Wmunu', 'Wtaunu'] # List of dataset codes to load\n",
    "#string_code_list = ['2to4lep', 'Zee', 'm10_40_Zee', 'Ztautau', 'ttbar', 'Wenu', 'Wtaunu'] # List of dataset codes to load\n",
    "\n",
    "# Specify the variables to be read in.\n",
    "# These variables will also be written out, in addition to any defined in the function 'preselection_cut' below\n",
    "read_variables = ['lep_n', 'lep_pt', 'lep_eta', 'lep_phi', 'lep_e', 'lep_ptvarcone30', 'lep_topoetcone20', 'lep_type', 'lep_charge', 'trigE', 'trigM', 'lep_isTrigMatched',\n",
    "                   'lep_isLooseID', 'lep_isMediumID', 'lep_isLooseIso', 'lep_isTightIso']\n",
    "\n",
    "# Alternatively, you may wish to use the pre-defined function `validate_read_variables` to find the names of all available variables\n",
    "#read_variables = get_valid_variables('2to4lep') # Save all available variables\n",
    "\n",
    "# Specify the directory to which the output parquet files should be written\n",
    "output_dir = '../../output-parquet/dimuon_massGT15_PtGT15'\n",
    "\n",
    "# Custom selection cut function to filter the data when writing out parquet files\n",
    "def preselection_cut(data):\n",
    "    # Use bitwise operator '&' for AND, '|' for OR. Remember to put parentheses around each logical (sub)expression!\n",
    "\n",
    "    # Cut on lepton number - Only keep events that have two leptons\n",
    "    data = data[data['lep_n'] == 2] \n",
    "\n",
    "    # Cut on lep_type\n",
    "    # lep_type is 11 for electron, 13 for muon\n",
    "    #data = data[data['lep_type'][:, 0] + data['lep_type'][:, 1] == 22] # Keep events with two electrons\n",
    "    data = data[data['lep_type'][:, 0] + data['lep_type'][:, 1] == 26] # Keep events with two muons\n",
    "\n",
    "    # Require that a single electron trigger fired \n",
    "    #data = data[(data['trigE'])] \n",
    "    # Require that a single muon trigger fired \n",
    "    data = data[(data['trigM'])] \n",
    "\n",
    "    # Require at least one lepton to have  pt > 27 GeV and be trigger matched\n",
    "    # N.B. not needed here because this has already been required in the pre-selection of the parquet files you are reaeding in\n",
    "    #data = data[((data['lep_pt'][:, 0] > 27) & (data['lep_isTrigMatched'][:, 0])) | ((data['lep_pt'][:, 1] > 27) & (data['lep_isTrigMatched'][:, 1]))]\n",
    "\n",
    "    # Find the pt of the lepton with the lowest pt of the two and add this variable to the data to be stored on the output parquet files\n",
    "    data['soft_pt'] = ((data['lep_pt'][:, 0] > data['lep_pt'][:, 1])*data['lep_pt'][:, 1]) + ((data['lep_pt'][:, 0] < data['lep_pt'][:, 1])*data['lep_pt'][:, 0])\n",
    "\n",
    "    # Cut on lepton pt - Keep events where both leptons have pt > 15 GeV\n",
    "    # Use bitwise operator '&' for AND, '|' for OR. Remember the parentheses!\n",
    "    LoosePt = 15\n",
    "    data = data[(data['lep_pt'][:, 0] > LoosePt) & (data['lep_pt'][:, 1] > LoosePt)]\n",
    "\n",
    "    # Define four momentum\n",
    "    four_momentum = vector.zip({\n",
    "        'pt': data['lep_pt'],\n",
    "        'eta' : data['lep_eta'],\n",
    "        'phi' : data['lep_phi'],\n",
    "        'E' : data['lep_e']\n",
    "    })\n",
    "    # Add the 4-momentum of the two leptons in each event and get the invariant mass using .M\n",
    "    data['mass'] = (four_momentum[:, 0] + four_momentum[:, 1]).M\n",
    "    \n",
    "    # Cut on di-lepton mass\n",
    "    cut_low = 15\n",
    "    cut_high = 1000   \n",
    "    cut_mass = (data['mass']>cut_low) &  (data['mass']<cut_high)\n",
    "    data = data[cut_mass] # Select events satisfying the condition: cut_low < mass < cut_high (GeV)\n",
    "        \n",
    "    # Tip: if you want to plot a variable that is a mathematical function of one or more of the input variables then do something like the following: \n",
    "    # Calculate the product of the charges of the two leptons.  \n",
    "    data['charge_product'] = data['lep_charge'][:, 0] * data['lep_charge'][:, 1]\n",
    "\n",
    "    # Select same-sign (['charge_product']>0), or opposite-sign (['charge_product']<0) events\n",
    "    #data = data[data['charge_product']<0]\n",
    " \n",
    "    return data\n",
    "\n",
    "fraction = 0.02\n",
    "\n",
    "# The argument \"write_parquet=True\" tells the function to write new parquet files to the output directory \"output_dir\"\n",
    "# The argument \"return_output=False\" tells the function NOT to store data from the selected events to memory (Needed to avoid overflowing the memory limit for fraction = 1)\n",
    "analysis_parquet(read_variables, string_code_list, fraction=fraction, cut_function=preselection_cut, write_parquet=True, output_directory=output_dir, return_output=False)\n",
    "\n",
    "# In order to make plots from these new parquet files you need to read them back in using the next cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6726654-b13d-4bc5-aeac-2d49592b4997",
   "metadata": {},
   "source": [
    "Files saved by `analysis_parquet` can be reloaded using the same function by specifying the following optional arguments:\n",
    "- `read_directory` : Path to the directory where the data is saved.\n",
    "- `subdirectory_names` : A list of subdirectories (folder names) to read from. If not provided, all subdirectories in `read_directory` will be read.\n",
    "  \n",
    "Note that `string_code_list` is also an optional argument with a default of `None`. Either `string_code_list` _**or**_ `read_directory` must be provided to the `analysis_parquet` function.  \n",
    "\n",
    "**_Tip_**: Before loading large datasets, it is recommended to restart the kernel to free up memory. Avoid reading too many variables at once to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f137d3f-b01b-42e6-a240-2b678a93f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your private di-lepton analysis parquet files and store the required data in memory\n",
    "\n",
    "read_directory = '../../output-parquet/dimuon_massGT15_PtGT15' # Directory where data was saved when running the previous cell\n",
    "# N.B. the '../../' in the directory name means that the output directory is created in your \"home\" directory rather then getting mixed up with your code\n",
    "get_valid_variables('2to4lep')\n",
    "\n",
    "# Specify which variables you want to read in for each event\n",
    "read_variables = ['mass', 'charge_product']\n",
    "#read_variables = ['lep_n', 'lep_pt', 'lep_eta', 'lep_phi', 'lep_e', 'lep_ptvarcone30', 'lep_topoetcone20', 'lep_type', 'lep_charge', 'trigE', 'trigM', 'lep_isTrigMatched',\n",
    "#                   'lep_isLooseID', 'lep_isMediumID', 'lep_isLooseIso', 'lep_isTightIso', 'soft_pt', 'charge_product']\n",
    "\n",
    "fraction = 1\n",
    "\n",
    "# Custom selection cut function to filter the data\n",
    "def read_parquet_cut(data):\n",
    "\n",
    "    # Cut on lep_type\n",
    "    # lep_type is 11 for electron, 13 for muon\n",
    "    #data = data[data['lep_type'][:, 0] + data['lep_type'][:, 1] == 26]\n",
    "\n",
    "    # Cut on di-lepton mass\n",
    "    cut_low = 85\n",
    "    cut_high = 95   \n",
    "    cut_mass = (data['mass']>cut_low) &  (data['mass']<cut_high)\n",
    "    data = data[cut_mass] # Select events satisfying the condition: cut_low < mass < cut_high (GeV)\n",
    "\n",
    "    # Select same-sign (['charge_product']>0), or opposite-sign (['charge_product']<0) events\n",
    "    data = data[data['charge_product']<0]\n",
    " \n",
    "    \n",
    "    return data\n",
    "    \n",
    "pt_data = analysis_parquet(read_variables, string_code_list=None, read_directory=read_directory,\n",
    "                        subdirectory_names=None, fraction=fraction, cut_function=read_parquet_cut,\n",
    "                        write_parquet=False, output_directory=None, return_output=True)\n",
    "pt_data\n",
    "\n",
    "# You can now in principle use all of the various plotting functions in the cells above on the data you have now stored in memory.\n",
    "# N.B. In the plotting functions you will need to change the names of the items in \"plot_dict\" to correspond to the keys written out below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da313b1-0206-4925-a5a9-e88a1f7bc8e2",
   "metadata": {},
   "source": [
    "Note the *change* in the keys of the output dictionary. Each key is constructed by combining the subdirectory name with the `fraction`, separated with`' x'`.  \n",
    "For example, if the subdirectory name is `'Zee_0_01'` and `fraction = 0.1`, the resulting key will be `'Zee_0_01 x0_1'`, implying that the sample represents `0.01 × 0.1` of the original dataset.  \n",
    "However, this naming convention does not reflect whether any cuts have been applied, hence the actual number of events is likely not this fraction of the full data —  it only provides a rough estimate. So, make sure to **record** your output directories and cuts clearly in your lab book!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50505cf2-9a39-40c1-8ef5-0b4fcf64842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Function 'produced_event_count' returns the total number (sum of weights) of generated Monte Carlo events for the data set specified by 'dataKey' and the specificed integrated luminosity.\n",
    "# You will need this as the denominator in the calculation of the selection efficiency for your signal processes\n",
    "luminosity = 36.6\n",
    "produced_event_count('Zmumu',luminosity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
